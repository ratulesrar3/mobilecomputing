{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Detection using IMU Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import peakutils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing helper functions to process the IMU data\n",
    "We just need to run master() once to have a nice dataframe of all the acclerometer data and related generated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run cleaner.py\n",
    "master = master()\n",
    "master.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating splits for training and test\n",
    "We train with 67% of the data and test on 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = splits(master, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting hyperparameters for the linear SVM model and initialising the validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_params = np.logspace(-6, 3, 10)\n",
    "svc_2 = LinearSVC(random_state = 1234)\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    svc_2, X_train.values, y_train.values.flatten(),\n",
    "    param_name=\"C\", param_range=C_params,\n",
    "    cv=2, scoring=\"accuracy\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_min = 0.5\n",
    "y_max = 1.1\n",
    "\n",
    "f = plt.figure(figsize = (12, 8))\n",
    "ax = plt.axes()\n",
    "sns.set(font_scale = 1.25)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.title(\"SVM Training and Validation Accuracy\")\n",
    "plt.xlabel(\"C Value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.yticks(np.arange(y_min, y_max + .01, .05))\n",
    "plt.semilogx(C_params, train_scores_mean, label=\"CV Training Accuracy\", color=\"red\")\n",
    "plt.fill_between(C_params, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"red\")\n",
    "plt.semilogx(C_params, test_scores_mean, label=\"CV Validation Accuracy\",\n",
    "             color=\"green\")\n",
    "plt.fill_between(C_params, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"green\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the grid search model\n",
    "We use rbf and linear kernel classification and output our modelâ€™s accuracy score and baseline accuracy for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train gridsearch model\n",
    "# using rbf and linear kernel\n",
    "Cs = np.logspace(-6, 3, 10)\n",
    "parameters = [{'kernel': ['rbf'], 'C': Cs},\n",
    "              {'kernel': ['linear'], 'C': Cs}]\n",
    "\n",
    "svc = SVC(random_state = 1234)\n",
    "\n",
    "clf = GridSearchCV(estimator = svc, param_grid = parameters, cv = 2, n_jobs = -1)\n",
    "clf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best estimator and best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy score for the best estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "This is the accuracy score we would get if we had no features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.value_counts().values[0] / y_test.value_counts().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe of activity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_desc_df = pd.DataFrame(master.activity.unique().tolist(), columns = ['activity'])\n",
    "label_num_df = pd.DataFrame(master.activity_factor.unique().tolist(), columns = ['activity_factor'])\n",
    "activity_df = pd.concat([label_num_df, label_desc_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosstab for displaying model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crosstab = pd.crosstab(y_test.values.flatten(), clf.predict(X_test),\n",
    "                          rownames=['True'], colnames=['Predicted'],\n",
    "                          margins=True)\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled version of crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crosstab_clean = crosstab.iloc[:-1, :-1]\n",
    "crosstab_clean.columns = activity_df.activity.values\n",
    "crosstab_clean.index = activity_df.activity_factor.values\n",
    "crosstab_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting test cases using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = test()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
